// Script principal pour extraire les donn√©es et t√©l√©charger toutes les images

// Import conditionnel selon l'environnement

// Fonction pour initialiser le t√©l√©chargeur selon l'environnement
async function initializeImageDownloader() {
  if (typeof window !== 'undefined') {
    // Environnement browser : utiliser la version browser-safe
    const { default: BrowserImageDownloader } = await import('../src/scripts/downloadImagesBrowser.js')
    return new BrowserImageDownloader()
  } else {
    // Environnement Node.js : utiliser la version compl√®te
    const { default: NodeImageDownloader } = await import('./downloadImages.js')
    return new NodeImageDownloader()
  }
}

class DataExtractor {
  constructor() {
    this.baseApiUrl = 'https://api.dofusdb.fr'
    this.dbUrl = import.meta.env?.DEV
      ? 'http://localhost:8888/.netlify/functions/database'
      : '/.netlify/functions/database'
    this.imageDownloader = null // Sera initialis√© plus tard

    this.extractedItems = new Map()
    this.extractedResources = new Map()
    this.recipes = []

    // Configuration depuis les variables d'environnement (GitHub Actions)
    this.forceDownload = (typeof process !== 'undefined' && process.env?.FORCE_DOWNLOAD === 'true') || false
    this.maxImages = (typeof process !== 'undefined' && parseInt(process.env?.MAX_IMAGES)) || 0

    console.log(`üîß Configuration:`)
    console.log(`   Force download: ${this.forceDownload}`)
    console.log(`   Max images: ${this.maxImages || 'illimit√©'}`)
  }

  // R√©cup√©rer tous les m√©tiers
  async fetchAllJobs() {
    console.log('üîç R√©cup√©ration de tous les m√©tiers...')
    
    try {
      const response = await fetch(`${this.baseApiUrl}/jobs`)
      if (!response.ok) throw new Error(`HTTP ${response.status}`)
      
      const jobs = await response.json()
      console.log(`‚úÖ ${jobs.data.length} m√©tiers trouv√©s`)
      
      return jobs.data
    } catch (error) {
      console.error('‚ùå Erreur r√©cup√©ration m√©tiers:', error)
      return []
    }
  }

  // R√©cup√©rer toutes les recettes d'un m√©tier
  async fetchJobRecipes(jobId) {
    console.log(`üîç R√©cup√©ration recettes m√©tier ${jobId}...`)
    
    try {
      let allRecipes = []
      let skip = 0
      const limit = 100
      
      while (true) {
        const url = `${this.baseApiUrl}/recipes?jobId=${jobId}&$limit=${limit}&$skip=${skip}`
        const response = await fetch(url)
        
        if (!response.ok) throw new Error(`HTTP ${response.status}`)
        
        const data = await response.json()
        const recipes = data.data || []
        
        if (recipes.length === 0) break
        
        allRecipes.push(...recipes)
        skip += limit
        
        console.log(`üì¶ ${allRecipes.length} recettes r√©cup√©r√©es...`)
        
        // Pause pour √™tre sympa avec l'API
        await new Promise(resolve => setTimeout(resolve, 200))
      }
      
      console.log(`‚úÖ ${allRecipes.length} recettes totales pour m√©tier ${jobId}`)
      return allRecipes
      
    } catch (error) {
      console.error(`‚ùå Erreur r√©cup√©ration recettes m√©tier ${jobId}:`, error)
      return []
    }
  }

  // Extraire les donn√©es d'un item
  extractItemData(recipe, jobName) {
    if (!recipe.result || !recipe.result.name?.fr) return null
    
    const item = recipe.result
    
    return {
      m_id: item.id,
      name_fr: item.name.fr,
      level: item.level || 1,
      type_id: item.typeId || 0,
      icon_id: item.iconId,
      profession: jobName,
      image_path: `/images/items/${item.iconId}.png`
    }
  }

  // Extraire les donn√©es d'une ressource
  extractResourceData(ingredient) {
    if (!ingredient || !ingredient.name?.fr) return null
    
    return {
      m_id: ingredient.id,
      name_fr: ingredient.name.fr,
      level: ingredient.level || 1,
      icon_id: ingredient.iconId,
      image_path: `/images/resources/${ingredient.iconId}.png`
    }
  }

  // Traiter toutes les recettes d'un m√©tier
  async processJobRecipes(jobId, jobName) {
    console.log(`\nüîß Traitement du m√©tier: ${jobName}`)
    
    const recipes = await this.fetchJobRecipes(jobId)
    let processedCount = 0
    
    for (const recipe of recipes) {
      try {
        // Extraire l'item
        const itemData = this.extractItemData(recipe, jobName)
        if (itemData) {
          this.extractedItems.set(itemData.m_id, itemData)
        }
        
        // Extraire les ressources et cr√©er les recettes
        if (recipe.ingredients && recipe.ingredientIds && recipe.quantities) {
          for (let i = 0; i < recipe.ingredients.length; i++) {
            const ingredient = recipe.ingredients[i]
            const quantity = recipe.quantities[i] || 1
            
            // Extraire la ressource
            const resourceData = this.extractResourceData(ingredient)
            if (resourceData) {
              this.extractedResources.set(resourceData.m_id, resourceData)
              
              // Cr√©er la liaison recette
              if (itemData) {
                this.recipes.push({
                  item_id: itemData.m_id,
                  resource_id: resourceData.m_id,
                  quantity: quantity
                })
              }
            }
          }
        }
        
        processedCount++
        
      } catch (error) {
        console.error(`‚ö†Ô∏è Erreur traitement recette:`, error)
      }
    }
    
    console.log(`‚úÖ ${processedCount} recettes trait√©es pour ${jobName}`)
  }

  // Extraire toutes les donn√©es
  async extractAllData() {
    console.log('üöÄ D√âBUT DE L\'EXTRACTION COMPL√àTE')
    console.log('===================================')

    // Initialiser le t√©l√©chargeur d'images
    if (!this.imageDownloader) {
      this.imageDownloader = await initializeImageDownloader()
    }

    // Cr√©er les dossiers pour les images
    this.imageDownloader.createDirectories()
    
    // R√©cup√©rer tous les m√©tiers
    const jobs = await this.fetchAllJobs()
    
    if (jobs.length === 0) {
      console.error('‚ùå Aucun m√©tier trouv√©, arr√™t du script')
      return
    }
    
    // Traiter chaque m√©tier
    for (const job of jobs) {
      if (job.name?.fr) {
        await this.processJobRecipes(job.id, job.name.fr)
        
        // Pause entre les m√©tiers
        await new Promise(resolve => setTimeout(resolve, 1000))
      }
    }
    
    console.log('\nüìä R√âSUM√â DE L\'EXTRACTION')
    console.log('==========================')
    console.log(`üì¶ Items extraits: ${this.extractedItems.size}`)
    console.log(`üß± Ressources extraites: ${this.extractedResources.size}`)
    console.log(`üîó Recettes cr√©√©es: ${this.recipes.length}`)
  }

  // T√©l√©charger toutes les images
  async downloadAllImages() {
    console.log('\nüñºÔ∏è T√âL√âCHARGEMENT DES IMAGES')
    console.log('=============================')

    // Initialiser le t√©l√©chargeur d'images si pas d√©j√† fait
    if (!this.imageDownloader) {
      this.imageDownloader = await initializeImageDownloader()
    }

    // R√©cup√©rer tous les icon_ids
    let itemIconIds = Array.from(this.extractedItems.values())
      .map(item => item.icon_id)
      .filter(id => id)

    let resourceIconIds = Array.from(this.extractedResources.values())
      .map(resource => resource.icon_id)
      .filter(id => id)

    // Appliquer la limite si d√©finie
    if (this.maxImages > 0) {
      const halfLimit = Math.floor(this.maxImages / 2)
      itemIconIds = itemIconIds.slice(0, halfLimit)
      resourceIconIds = resourceIconIds.slice(0, halfLimit)
      console.log(`‚ö†Ô∏è Limite appliqu√©e: ${this.maxImages} images max`)
    }

    console.log(`üì¶ ${itemIconIds.length} images d'items √† t√©l√©charger`)
    console.log(`üß± ${resourceIconIds.length} images de ressources √† t√©l√©charger`)

    // Configurer le t√©l√©chargeur
    if (this.forceDownload) {
      console.log(`üîÑ Mode force: re-t√©l√©chargement des images existantes`)
    }

    // T√©l√©charger les images des items
    if (itemIconIds.length > 0) {
      await this.imageDownloader.downloadBatch(itemIconIds, 'items', 3)
    }

    // T√©l√©charger les images des ressources
    if (resourceIconIds.length > 0) {
      await this.imageDownloader.downloadBatch(resourceIconIds, 'resources', 3)
    }

    // Afficher le r√©sum√©
    this.imageDownloader.printSummary()
    this.imageDownloader.calculateTotalSize()
  }

  // Sauvegarder en base de donn√©es
  async saveToDatabase() {
    console.log('\nüíæ SAUVEGARDE EN BASE DE DONN√âES')
    console.log('=================================')
    
    try {
      // Sauvegarder les items
      const itemsArray = Array.from(this.extractedItems.values())
      console.log(`üì¶ Sauvegarde de ${itemsArray.length} items...`)
      
      // Sauvegarder les ressources
      const resourcesArray = Array.from(this.extractedResources.values())
      console.log(`üß± Sauvegarde de ${resourcesArray.length} ressources...`)
      
      // Sauvegarder les recettes
      console.log(`üîó Sauvegarde de ${this.recipes.length} recettes...`)
      
      // TODO: Impl√©menter les appels API vers la base de donn√©es
      console.log('‚ö†Ô∏è Sauvegarde BDD √† impl√©menter')
      
    } catch (error) {
      console.error('‚ùå Erreur sauvegarde BDD:', error)
    }
  }

  // V√©rifier si on a besoin d'extraire les donn√©es
  needsDataExtraction() {
    // Si on force le t√©l√©chargement, on extrait aussi
    if (this.forceDownload) {
      console.log('üîÑ Mode force: extraction des donn√©es n√©cessaire')
      return true
    }

    // En environnement Node.js, toujours extraire (pas de localStorage)
    if (typeof window === 'undefined') {
      console.log('üîÑ Environnement Node.js: extraction n√©cessaire')
      return true
    }

    // V√©rifier si on a d√©j√† des donn√©es r√©centes (moins de 24h) - seulement c√¥t√© client
    try {
      if (typeof localStorage !== 'undefined') {
        const lastExtraction = localStorage.getItem('last_data_extraction')
        if (lastExtraction) {
          const lastTime = parseInt(lastExtraction)
          const now = Date.now()
          const hoursSince = (now - lastTime) / (1000 * 60 * 60)

          if (hoursSince < 24) {
            console.log(`‚è≠Ô∏è Donn√©es extraites il y a ${hoursSince.toFixed(1)}h, skip extraction`)
            return false
          }
        }
      }
    } catch (error) {
      console.log('‚ö†Ô∏è Pas d\'acc√®s localStorage, extraction n√©cessaire')
    }

    console.log('üîÑ Extraction des donn√©es n√©cessaire')
    return true
  }

  // Ex√©cuter le script complet (optimis√©)
  async run() {
    const startTime = Date.now()

    try {
      // V√©rifier si l'extraction de donn√©es est n√©cessaire
      if (this.needsDataExtraction()) {
        await this.extractAllData()

        // Marquer la date d'extraction (seulement c√¥t√© client)
        try {
          if (typeof localStorage !== 'undefined') {
            localStorage.setItem('last_data_extraction', Date.now().toString())
          }
        } catch (error) {
          console.log('‚ö†Ô∏è Impossible de sauvegarder dans localStorage')
        }
      } else {
        console.log('‚è≠Ô∏è Skip extraction des donn√©es (r√©centes)')

        // Simuler quelques donn√©es pour le t√©l√©chargement d'images
        console.log('üì∏ Mode t√©l√©chargement d\'images uniquement')

        // R√©cup√©rer les IDs depuis les images existantes si possible
        await this.loadExistingImageIds()
      }

      await this.downloadAllImages()
      await this.saveToDatabase()

      const duration = (Date.now() - startTime) / 1000
      console.log(`\nüéâ EXTRACTION TERMIN√âE EN ${duration.toFixed(1)}s`)

    } catch (error) {
      console.error('‚ùå Erreur fatale:', error)
    }
  }

  // Charger les IDs depuis les images existantes (Node.js seulement)
  async loadExistingImageIds() {
    // V√©rifier qu'on est en environnement Node.js
    if (typeof window !== 'undefined') {
      console.log('‚ö†Ô∏è loadExistingImageIds: environnement navigateur, skip')
      return
    }

    try {
      const fs = await import('fs')
      const path = await import('path')

      const itemsDir = path.join(process.cwd(), 'public/images/items')
      const resourcesDir = path.join(process.cwd(), 'public/images/resources')

      let itemIds = []
      let resourceIds = []

      if (fs.existsSync(itemsDir)) {
        itemIds = fs.readdirSync(itemsDir)
          .filter(file => file.endsWith('.png'))
          .map(file => parseInt(file.replace('.png', '')))
          .filter(id => !isNaN(id))
      }

      if (fs.existsSync(resourcesDir)) {
        resourceIds = fs.readdirSync(resourcesDir)
          .filter(file => file.endsWith('.png'))
          .map(file => parseInt(file.replace('.png', '')))
          .filter(id => !isNaN(id))
      }

      console.log(`üìÇ Images existantes: ${itemIds.length} items, ${resourceIds.length} ressources`)

      // Cr√©er des objets factices pour le t√©l√©chargement
      itemIds.forEach(id => {
        this.extractedItems.set(id, { icon_id: id })
      })

      resourceIds.forEach(id => {
        this.extractedResources.set(id, { icon_id: id })
      })

    } catch (error) {
      console.warn('‚ö†Ô∏è Impossible de charger les IDs existants:', error.message)
    }
  }
}

// Ex√©cuter le script si appel√© directement
if (import.meta.url === `file://${process.argv[1]}`) {
  const extractor = new DataExtractor()
  extractor.run()
}

export default DataExtractor
